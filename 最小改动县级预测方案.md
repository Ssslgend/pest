# 最小改动县级预测方案

## 方案概述
不修改现有BiLSTM模型架构，仅通过数据处理方式实现县级预测

## 实现步骤

### 1. 数据预处理脚本

```python
# county_preprocessor.py
import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from sklearn.preprocessing import StandardScaler

class CountyDataProcessor:
    def __init__(self, original_feature_names):
        """
        初始化县级数据处理器
        
        Args:
            original_feature_names: 原始模型使用的特征名称列表
        """
        self.original_feature_names = original_feature_names
        self.scaler = StandardScaler()
        
    def aggregate_points_to_counties(self, raw_data):
        """
        将点数据聚合到县级
        
        Args:
            raw_data: 原始点数据DataFrame
            
        Returns:
            county_data: 县级数据字典
        """
        county_data = {}
        
        # 按县分组
        for county_name in raw_data['county_name'].unique():
            county_subset = raw_data[raw_data['county_name'] == county_name]
            
            # 按时间分组
            time_groups = county_subset.groupby(['year', 'month'])
            
            county_features = []
            county_labels = []
            
            for (year, month), group in time_groups:
                # 计算每个时间段的特征统计
                feature_vector = self._calculate_features(group)
                county_features.append(feature_vector)
                
                # 使用该县该时间段的主要标签
                county_labels.append(group['target'].mode()[0])
            
            county_data[county_name] = {
                'features': np.array(county_features),
                'labels': np.array(county_labels),
                'time_index': list(time_groups.groups.keys())
            }
        
        return county_data
    
    def _calculate_features(self, group_data):
        """
        计算县级特征（保持与原始模型相同的特征数量）
        """
        features = []
        
        # 对每个原始特征计算统计量
        for feature_name in self.original_feature_names:
            if feature_name in group_data.columns:
                values = group_data[feature_name].values
                # 计算基本统计量
                mean_val = np.mean(values)
                std_val = np.std(values) if len(values) > 1 else 0
                max_val = np.max(values)
                min_val = np.min(values)
                
                # 添加到特征向量
                features.extend([mean_val, std_val, max_val, min_val])
        
        # 确保特征数量匹配原始模型
        target_length = len(self.original_feature_names) * 4  # 每个特征4个统计量
        
        if len(features) > target_length:
            features = features[:target_length]
        elif len(features) < target_length:
            features.extend([0] * (target_length - len(features)))
        
        return np.array(features)
    
    def prepare_model_input(self, county_data, seq_length=8):
        """
        准备模型输入数据
        
        Args:
            county_data: 县级数据字典
            seq_length: 时间序列长度
            
        Returns:
            model_input: 模型输入数据
        """
        all_inputs = []
        all_labels = []
        county_names = []
        
        for county_name, data in county_data.items():
            features = data['features']
            labels = data['labels']
            
            # 创建时间序列样本
            for i in range(len(features) - seq_length + 1):
                sequence = features[i:i + seq_length]
                label = labels[i + seq_length - 1]
                
                all_inputs.append(sequence)
                all_labels.append(label)
                county_names.append(county_name)
        
        # 标准化
        if len(all_inputs) > 0:
            all_inputs = np.array(all_inputs)
            original_shape = all_inputs.shape
            all_inputs_flat = all_inputs.reshape(-1, original_shape[-1])
            all_inputs_scaled = self.scaler.fit_transform(all_inputs_flat)
            all_inputs = all_inputs_scaled.reshape(original_shape)
        
        return {
            'inputs': torch.tensor(all_inputs, dtype=torch.float32),
            'labels': torch.tensor(all_labels, dtype=torch.long),
            'county_names': county_names
        }

### 2. 县级预测器

```python
# county_predictor.py
import torch
import torch.nn.functional as F

class CountyPredictor:
    def __init__(self, trained_model, processor):
        """
        初始化县级预测器
        
        Args:
            trained_model: 训练好的原始BiLSTM模型
            processor: CountyDataProcessor实例
        """
        self.model = trained_model
        self.model.eval()
        self.processor = processor
    
    def predict_county_risk(self, raw_data):
        """
        预测县级风险
        
        Args:
            raw_data: 新的原始点数据
            
        Returns:
            county_predictions: 县级预测结果
        """
        # 预处理数据
        county_data = self.processor.aggregate_points_to_counties(raw_data)
        model_input = self.processor.prepare_model_input(county_data)
        
        # 预测
        predictions = {}
        
        with torch.no_grad():
            if len(model_input['inputs']) > 0:
                outputs = self.model(model_input['inputs'])
                
                # 获取预测概率
                probabilities = F.softmax(outputs, dim=1)
                predicted_classes = torch.argmax(probabilities, dim=1)
                
                # 按县聚合结果
                for i, county_name in enumerate(model_input['county_names']):
                    if county_name not in predictions:
                        predictions[county_name] = {
                            'risk_level': predicted_classes[i].item(),
                            'probabilities': probabilities[i].tolist(),
                            'prediction_count': 0
                        }
                    predictions[county_name]['prediction_count'] += 1
        
        # 计算每个县的最终风险等级
        final_predictions = {}
        for county_name, pred_data in predictions.items():
            # 如果有多个预测，取平均
            if pred_data['prediction_count'] > 1:
                avg_prob = np.mean(pred_data['probabilities'], axis=0)
                final_risk = np.argmax(avg_prob)
            else:
                avg_prob = pred_data['probabilities']
                final_risk = pred_data['risk_level']
            
            final_predictions[county_name] = {
                'risk_level': final_risk,
                'risk_probabilities': avg_prob.tolist(),
                'risk_description': self._get_risk_description(final_risk),
                'confidence': max(avg_prob)
            }
        
        return final_predictions
    
    def _get_risk_description(self, risk_level):
        """
        获取风险等级描述
        """
        descriptions = {
            0: "无风险",
            1: "低风险", 
            2: "中风险",
            3: "高风险"
        }
        return descriptions.get(risk_level, "未知")

### 3. 使用示例

```python
# example_usage.py
import pandas as pd
from county_preprocessor import CountyDataProcessor
from county_predictor import CountyPredictor
from model.bilstm import BiLSTMModel  # 你的原始模型

# 1. 加载训练好的模型
model = BiLSTMModel(config)  # 使用你的模型配置
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

# 2. 初始化处理器和预测器
original_features = ['Temperature', 'Humidity', 'Rainfall', 'WS', 'WD', 'Pressure', 'Sunshine', 'Visibility']
processor = CountyDataProcessor(original_features)
predictor = CountyPredictor(model, processor)

# 3. 准备新的预测数据
new_data = pd.read_csv('new_county_data.csv')  # 你的新数据

# 4. 进行县级预测
county_predictions = predictor.predict_county_risk(new_data)

# 5. 输出结果
print("县级美国白蛾风险预测结果:")
for county_name, result in county_predictions.items():
    print(f"{county_name}: {result['risk_description']} (置信度: {result['confidence']:.3f})")

# 6. 生成风险分布统计
risk_distribution = {
    '无风险': [],
    '低风险': [],
    '中风险': [],
    '高风险': []
}

for county_name, result in county_predictions.items():
    risk_level = result['risk_level']
    if risk_level == 0:
        risk_distribution['无风险'].append(county_name)
    elif risk_level == 1:
        risk_distribution['低风险'].append(county_name)
    elif risk_level == 2:
        risk_distribution['中风险'].append(county_name)
    elif risk_level == 3:
        risk_distribution['高风险'].append(county_name)

print("\n风险分布统计:")
for risk_level, counties in risk_distribution.items():
    print(f"{risk_level}: {len(counties)}个县")
    print(f"  县名: {', '.join(counties[:5])}{'...' if len(counties) > 5 else ''}")
```

### 4. 数据格式要求

```csv
# 输入数据格式示例
county_name,year,month,Temperature,Humidity,Rainfall,WS,WD,Pressure,Sunshine,Visibility,target
历下区,2024,1,2.5,65.3,10.2,3.1,180,1013.2,8.7,15.2,0
历下区,2024,1,2.8,63.1,8.5,2.8,175,1012.8,7.9,14.8,0
市中区,2024,1,1.8,62.1,8.5,2.5,170,1011.5,7.2,13.5,1
市中区,2024,1,2.1,60.8,7.2,2.2,165,1010.9,6.8,12.9,1
```

## 优势特点

1. **最小改动**: 不修改原有模型架构
2. **保持兼容**: 完全兼容现有训练数据格式
3. **易于实现**: 只需添加数据处理层
4. **可扩展**: 支持未来进一步优化
5. **性能保证**: 保持原有模型的预测能力

## 实施步骤

1. 将上述代码保存为独立文件
2. 准备县级粒度的原始数据
3. 使用现有模型进行预测
4. 聚合结果得到县级预测

这个方案可以在不修改你现有模型的情况下，实现从点预测到县级预测的转换。