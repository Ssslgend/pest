epoch,train_loss,val_loss,train_auc,val_auc,Model
1,0.7222,0.7011,0.4867,0.3636,MLP
2,0.6705,0.6803,0.594,0.5195,MLP
3,0.6603,0.6628,0.529,0.6104,MLP
4,0.6356,0.6483,0.6379,0.6234,MLP
5,0.5876,0.6356,0.7138,0.6364,MLP
6,0.6096,0.6247,0.6429,0.6623,MLP
7,0.5856,0.6168,0.7084,0.6883,MLP
8,0.6096,0.6098,0.6549,0.6883,MLP
9,0.6175,0.6036,0.6301,0.7013,MLP
10,0.6047,0.5985,0.6599,0.7143,MLP
11,0.5465,0.5943,0.7722,0.7143,MLP
12,0.557,0.59,0.7349,0.7273,MLP
13,0.5565,0.5868,0.739,0.7403,MLP
14,0.5545,0.5835,0.7191,0.7403,MLP
15,0.545,0.5803,0.7461,0.7532,MLP
16,0.5447,0.5778,0.7419,0.7532,MLP
17,0.5257,0.5756,0.7746,0.7532,MLP
18,0.549,0.5734,0.7345,0.7532,MLP
19,0.4823,0.5706,0.8422,0.7532,MLP
20,0.5223,0.5679,0.7713,0.7532,MLP
21,0.5038,0.5666,0.7954,0.7532,MLP
22,0.4995,0.5655,0.8186,0.7532,MLP
23,0.5159,0.5641,0.7883,0.7532,MLP
24,0.4976,0.5626,0.8032,0.7532,MLP
25,0.5092,0.5613,0.8049,0.7532,MLP
26,0.4686,0.5598,0.8355,0.7532,MLP
27,0.4863,0.5586,0.8231,0.7532,MLP
28,0.4976,0.5575,0.7991,0.7532,MLP
29,0.5011,0.5565,0.7995,0.7532,MLP
30,0.4993,0.5558,0.8007,0.7532,MLP
