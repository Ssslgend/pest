# å±±ä¸œå¿çº§ç¾å›½ç™½è›¾é¢„æµ‹æ¨¡å‹ä¿®æ”¹æ–¹æ¡ˆ

## é¡¹ç›®æ¦‚è¿°
ç°æœ‰BiLSTMæ¨¡å‹éœ€è¦ä»ç‚¹çº§åˆ«é¢„æµ‹å‡çº§åˆ°å±±ä¸œçœå¿çº§å°ºåº¦çš„ç¾å›½ç™½è›¾é£é™©é¢„æµ‹ã€‚

## é—®é¢˜åˆ†æ
### å½“å‰é—®é¢˜
1. **é¢„æµ‹å°ºåº¦ä¸åŒ¹é…**ï¼šå½“å‰æ¨¡å‹é€‚åˆæ—¶é—´åºåˆ—ç‚¹é¢„æµ‹ï¼Œä½†éœ€è¦å¿çº§ç©ºé—´é¢„æµ‹
2. **ç‰¹å¾ç»´åº¦ä¸è¶³**ï¼šinput_size=12ï¼Œä¸è¶³ä»¥æ”¯æŒå¿çº§å¤šç»´åº¦ç‰¹å¾
3. **ç¼ºä¹ç©ºé—´å…³ç³»**ï¼šæ²¡æœ‰è€ƒè™‘å¿çº§ä¹‹é—´çš„ç©ºé—´é‚»æ¥å…³ç³»
4. **æ•°æ®ç»“æ„ä¸é€‚åº”**ï¼šå½“å‰è®­ç»ƒæ•°æ®æ˜¯æ°´ç¨»å®³è™«ï¼Œä¸æ˜¯ç¾å›½ç™½è›¾

### ç›®æ ‡
- é¢„æµ‹å±±ä¸œçœ137ä¸ªå¿çº§å•ä½çš„ç¾å›½ç™½è›¾å‘ç”Ÿé£é™©
- è¾“å‡ºæ¯ä¸ªå¿çš„é£é™©ç­‰çº§ï¼ˆ0-3çº§ï¼‰å’Œå‘ç”Ÿæ¦‚ç‡
- è€ƒè™‘æ—¶é—´åºåˆ—ç‰¹å¾å’Œç©ºé—´ä¼ æ’­ç‰¹å¾

---

## ğŸ“Š æ•°æ®ç»“æ„è°ƒæ•´æ–¹æ¡ˆ

### è¾“å…¥æ•°æ®æ ¼å¼ä¿®æ”¹

#### åŸå§‹æ•°æ®æ ¼å¼ï¼ˆç¤ºä¾‹ï¼‰
```csv
county_name,year,month,occurrence_status
æµå—å†ä¸‹åŒº,2023,1,0
æµå—å†ä¸‹åŒº,2023,2,1
é’å²›å¸‚å—åŒº,2023,1,0
```

#### ç›®æ ‡æ•°æ®æ ¼å¼ï¼ˆ30ç»´ç‰¹å¾ï¼‰
```csv
county_id,county_name,year,month,avg_temp,precipitation,humidity,ndvi,population,forest_coverage,elevation,latitude,longitude,neighboring_risk,historical_occurrence,target
370101,å†ä¸‹åŒº,2023,1,2.5,10.2,65.3,0.45,1500000,0.35,120.5,36.7,0.15,0,0
370102,å¸‚ä¸­åŒº,2023,1,1.8,8.5,62.1,0.42,1200000,0.28,118.3,36.2,0.12,1,1
```

### ç‰¹å¾ç»´åº¦æ‰©å±•ï¼ˆ30ç»´ï¼‰

#### 1. æ°”è±¡ç‰¹å¾ï¼ˆ8ç»´ï¼‰
- avg_temp: æœˆå¹³å‡æ¸©åº¦
- max_temp: æœˆæœ€é«˜æ¸©åº¦  
- min_temp: æœˆæœ€ä½æ¸©åº¦
- precipitation: æœˆé™æ°´é‡
- humidity: ç›¸å¯¹æ¹¿åº¦
- wind_speed: é£é€Ÿ
- sunshine: æ—¥ç…§æ—¶æ•°
- pressure: æ°”å‹

#### 2. åœ°ç†ç‰¹å¾ï¼ˆ4ç»´ï¼‰
- elevation: æµ·æ‹”é«˜åº¦
- slope: å¡åº¦
- latitude: çº¬åº¦
- longitude: ç»åº¦

#### 3. æ¤è¢«ç‰¹å¾ï¼ˆ3ç»´ï¼‰
- ndvi: å½’ä¸€åŒ–æ¤è¢«æŒ‡æ•°
- evi: å¢å¼ºæ¤è¢«æŒ‡æ•°
- forest_coverage: æ£®æ—è¦†ç›–ç‡

#### 4. ç¤¾ä¼šç»æµç‰¹å¾ï¼ˆ3ç»´ï¼‰
- population: äººå£æ•°é‡
- gdp: åœ°åŒºç”Ÿäº§æ€»å€¼
- agricultural_area: å†œä¸šç”¨åœ°é¢ç§¯

#### 5. å†å²ç‰¹å¾ï¼ˆ2ç»´ï¼‰
- historical_occurrence: å†å²å‘ç”Ÿæ¬¡æ•°
- neighboring_risk: é‚»æ¥å¿é£é™©æŒ‡æ•°

#### 6. æ—¶é—´ç‰¹å¾ï¼ˆ2ç»´ï¼‰
- month: æœˆä»½ï¼ˆ1-12ï¼‰
- season: å­£èŠ‚ï¼ˆ1-4ï¼‰

#### 7. å¿çº§åµŒå…¥ç‰¹å¾ï¼ˆ8ç»´ï¼‰
- é€šè¿‡Embeddingå±‚å­¦ä¹ å¿çº§ç‰¹æœ‰ç‰¹å¾

### ç©ºé—´é‚»æ¥çŸ©é˜µæ„å»º

```python
# å±±ä¸œå¿çº§é‚»æ¥å…³ç³»ç¤ºä¾‹
adjacency_matrix = {
    370101: [370102, 370103, 370112],  # å†ä¸‹åŒºç›¸é‚»å¿
    370102: [370101, 370103, 370105],  # å¸‚ä¸­åŒºç›¸é‚»å¿
    # ... æ‰€æœ‰137ä¸ªå¿çš„é‚»æ¥å…³ç³»
}

# é‚»æ¥çŸ©é˜µè®¡ç®—æ–¹å¼
def calculate_adjacency(county_coords, threshold=50):
    """
    county_coords: {county_id: (lat, lon)}
    threshold: é‚»æ¥è·ç¦»é˜ˆå€¼ï¼ˆå…¬é‡Œï¼‰
    """
    adjacency = {}
    for county1, coord1 in county_coords.items():
        neighbors = []
        for county2, coord2 in county_coords.items():
            if county1 != county2:
                distance = haversine(coord1, coord2)
                if distance <= threshold:
                    neighbors.append(county2)
        adjacency[county1] = neighbors
    return adjacency
```

---

## ğŸ¯ æ¨¡å‹é¢„æµ‹è¾“å‡ºæ ¼å¼

### è¾“å‡º1: é£é™©ç­‰çº§é¢„æµ‹
```python
# æ¯ä¸ªå¿çš„é£é™©ç­‰çº§ï¼ˆ0-3ï¼‰
output = {
    'county_id': [370101, 370102, 370103, ...],
    'county_name': ['å†ä¸‹åŒº', 'å¸‚ä¸­åŒº', 'æ§è«åŒº', ...],
    'risk_level': [0, 1, 2, 0, 3, 1, ...],  # 0:æ— é£é™©, 1:ä½é£é™©, 2:ä¸­é£é™©, 3:é«˜é£é™©
    'probability': [0.1, 0.3, 0.6, 0.2, 0.9, 0.4, ...],  # é£é™©æ¦‚ç‡
    'prediction_month': '2024-06'
}
```

### è¾“å‡º2: å‘ç”Ÿæ¦‚ç‡é¢„æµ‹
```python
# æ¯ä¸ªå¿çš„å‘ç”Ÿæ¦‚ç‡ï¼ˆ0-1ï¼‰
output = {
    'county_predictions': {
        '370101': {'name': 'å†ä¸‹åŒº', 'probability': 0.15, 'risk': 'low'},
        '370102': {'name': 'å¸‚ä¸­åŒº', 'probability': 0.75, 'risk': 'high'},
        '370103': {'name': 'æ§è«åŒº', 'probability': 0.45, 'risk': 'medium'},
        # ... æ‰€æœ‰137ä¸ªå¿
    },
    'prediction_date': '2024-06-01',
    'model_version': 'county_level_v1'
}
```

### è¾“å‡º3: ç©ºé—´åˆ†å¸ƒå¯è§†åŒ–æ•°æ®
```python
# å¯è§†åŒ–è¾“å‡º
output = {
    'map_data': {
        'counties': [æ‰€æœ‰å¿çš„å¤šè¾¹å½¢æ•°æ®],
        'risk_values': [æ¯ä¸ªå¿çš„é£é™©å€¼],
        'color_scale': 'green_to_red'
    },
    'summary': {
        'high_risk_counties': 15,
        'medium_risk_counties': 32,
        'low_risk_counties': 45,
        'no_risk_counties': 45
    }
}
```

### é£é™©ç­‰çº§å®šä¹‰
- **0çº§ï¼ˆæ— é£é™©ï¼‰**ï¼šå‘ç”Ÿæ¦‚ç‡ < 0.2
- **1çº§ï¼ˆä½é£é™©ï¼‰**ï¼š0.2 â‰¤ å‘ç”Ÿæ¦‚ç‡ < 0.4
- **2çº§ï¼ˆä¸­é£é™©ï¼‰**ï¼š0.4 â‰¤ å‘ç”Ÿæ¦‚ç‡ < 0.7
- **3çº§ï¼ˆé«˜é£é™©ï¼‰**ï¼šå‘ç”Ÿæ¦‚ç‡ â‰¥ 0.7

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„ä¿®æ”¹æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: ç©ºé—´å¢å¼ºå‹BiLSTMï¼ˆæ¨èï¼‰

**æ ¸å¿ƒæ€è·¯**ï¼šä¿ç•™BiLSTMçš„æ—¶é—´åºåˆ—èƒ½åŠ›ï¼Œå¢åŠ ç©ºé—´ç‰¹å¾å’Œå¿çº§æ³¨æ„åŠ›

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class CountyLevelBiLSTM(nn.Module):
    def __init__(self, config):
        super().__init__()
        
        # ç‰¹å¾ç»´åº¦
        self.input_size = 30  # æ‰©å±•åçš„ç‰¹å¾ç»´åº¦
        self.county_count = 137  # å±±ä¸œå¿çº§æ•°é‡
        self.hidden_size = 256
        self.num_classes = 4
        
        # 1. å¿çº§åµŒå…¥å±‚ï¼ˆå­¦ä¹ æ¯ä¸ªå¿çš„ç‰¹æœ‰ç‰¹å¾ï¼‰
        self.county_embedding = nn.Embedding(self.county_count, 16)
        
        # 2. ç‰¹å¾ç¼–ç å™¨
        self.feature_encoder = nn.Sequential(
            nn.Linear(self.input_size + 16, 128),  # +16æ˜¯å¿çº§åµŒå…¥
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64)
        )
        
        # 3. æ—¶é—´åºåˆ—BiLSTM
        self.lstm = nn.LSTM(
            input_size=64,
            hidden_size=self.hidden_size,
            num_layers=3,
            batch_first=True,
            bidirectional=True,
            dropout=0.3
        )
        
        # 4. ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶
        self.spatial_attention = nn.MultiheadAttention(
            embed_dim=self.hidden_size * 2,
            num_heads=8,
            dropout=0.1
        )
        
        # 5. è¾“å‡ºå±‚
        self.classifier = nn.Sequential(
            nn.Linear(self.hidden_size * 2, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, self.num_classes)
        )
        
    def forward(self, features, county_ids, spatial_adjacency):
        """
        features: [batch_size, seq_len, input_size]
        county_ids: [batch_size] å¿çº§ID
        spatial_adjacency: [batch_size, batch_size] ç©ºé—´é‚»æ¥çŸ©é˜µ
        """
        batch_size, seq_len, _ = features.shape
        
        # 1. æ·»åŠ å¿çº§åµŒå…¥
        county_emb = self.county_embedding(county_ids)  # [batch_size, 16]
        county_emb = county_emb.unsqueeze(1).expand(-1, seq_len, -1)  # [batch_size, seq_len, 16]
        
        # 2. ç‰¹å¾èåˆ
        combined_features = torch.cat([features, county_emb], dim=-1)
        encoded_features = self.feature_encoder(combined_features)  # [batch_size, seq_len, 64]
        
        # 3. æ—¶é—´åºåˆ—å¤„ç†
        lstm_out, _ = self.lstm(encoded_features)  # [batch_size, seq_len, hidden_size*2]
        
        # 4. ç©ºé—´æ³¨æ„åŠ›
        spatial_out, _ = self.spatial_attention(
            lstm_out[:, -1, :].unsqueeze(0),  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
            lstm_out[:, -1, :].unsqueeze(0),
            lstm_out[:, -1, :].unsqueeze(0)
        )
        spatial_out = spatial_out.squeeze(0)  # [batch_size, hidden_size*2]
        
        # 5. æœ€ç»ˆåˆ†ç±»
        output = self.classifier(spatial_out)  # [batch_size, num_classes]
        
        return output
```

### æ–¹æ¡ˆ2: å›¾ç¥ç»ç½‘ç»œï¼ˆGCNï¼‰

**ä¼˜åŠ¿**ï¼šä¸“é—¨å¤„ç†ç©ºé—´å…³ç³»ï¼Œé€‚åˆå¿çº§å°ºåº¦

```python
import torch_geometric.nn as pyg_nn

class CountyGCN(nn.Module):
    def __init__(self, num_counties, input_dim, hidden_dim, num_classes):
        super().__init__()
        
        # å›¾å·ç§¯å±‚
        self.conv1 = pyg_nn.GCNConv(input_dim, hidden_dim)
        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim // 2)
        self.conv3 = pyg_nn.GCNConv(hidden_dim // 2, num_classes)
        
        # å¿çº§ç‰¹å¾
        self.county_embeddings = nn.Parameter(torch.randn(num_counties, input_dim))
        
    def forward(self, edge_index, features=None):
        """
        edge_index: å›¾çš„è¾¹è¿æ¥ [2, num_edges]
        features: å¯é€‰çš„å¤–éƒ¨ç‰¹å¾
        """
        if features is not None:
            x = torch.cat([self.county_embeddings, features], dim=-1)
        else:
            x = self.county_embeddings
            
        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, p=0.3, training=self.training)
        x = F.relu(self.conv2(x, edge_index))
        x = self.conv3(x, edge_index)
        
        return F.log_softmax(x, dim=1)
```

### æ–¹æ¡ˆ3: é›†æˆæ¨¡å‹ï¼ˆæœ€å‡†ç¡®ï¼‰

```python
class CountyEnsembleModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        
        # 1. BiLSTMåˆ†æ”¯ï¼ˆæ—¶é—´ç‰¹å¾ï¼‰
        self.temporal_model = CountyLevelBiLSTM(config)
        
        # 2. GCNåˆ†æ”¯ï¼ˆç©ºé—´ç‰¹å¾ï¼‰
        self.spatial_model = CountyGCN(
            num_counties=config['num_counties'],
            input_dim=config['spatial_input_dim'],
            hidden_dim=config['hidden_size'],
            num_classes=config['num_classes']
        )
        
        # 3. é›†æˆå±‚
        self.ensemble = nn.Linear(config['num_classes'] * 2, config['num_classes'])
        
    def forward(self, temporal_features, county_ids, edge_index, spatial_features):
        # æ—¶é—´åˆ†æ”¯
        temporal_output = self.temporal_model(temporal_features, county_ids, edge_index)
        
        # ç©ºé—´åˆ†æ”¯  
        spatial_output = self.spatial_model(edge_index, spatial_features)
        
        # é›†æˆ
        combined = torch.cat([temporal_output, spatial_output], dim=-1)
        final_output = self.ensemble(combined)
        
        return final_output
```

---

## ğŸ¯ å…·ä½“å®æ–½æ–¹æ¡ˆ

### æ­¥éª¤1: æ•°æ®å‡†å¤‡

1. **æ„å»ºå¿çº§ç‰¹å¾è¡¨**ï¼ˆ30ç»´ç‰¹å¾ï¼‰
   - æ°”è±¡æ•°æ®æ¥æºï¼šå›½å®¶æ°”è±¡å±€ã€ECMWFå†åˆ†ææ•°æ®
   - åœ°ç†æ•°æ®æ¥æºï¼šSRTMé«˜ç¨‹æ•°æ®ã€å±±ä¸œåœ°ç†ä¿¡æ¯æ•°æ®
   - æ¤è¢«æ•°æ®æ¥æºï¼šMODIS NDVI/EVIæ•°æ®
   - ç¤¾ä¼šç»æµæ•°æ®ï¼šå±±ä¸œç»Ÿè®¡å¹´é‰´

2. **æ•°æ®é¢„å¤„ç†**
   ```python
   def preprocess_county_data(raw_data):
       """
       é¢„å¤„ç†å¿çº§æ•°æ®
       """
       # æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾
       scaler = StandardScaler()
       numerical_features = ['avg_temp', 'precipitation', 'population', ...]
       raw_data[numerical_features] = scaler.fit_transform(raw_data[numerical_features])
       
       # ç¼–ç åˆ†ç±»ç‰¹å¾
       raw_data['season'] = raw_data['month'].apply(get_season)
       
       # è®¡ç®—é‚»åŸŸé£é™©
       raw_data['neighboring_risk'] = calculate_neighboring_risk(
           raw_data, adjacency_matrix
       )
       
       return raw_data
   ```

### æ­¥éª¤2: æ¨¡å‹é…ç½®

```python
# æ›´æ–°é…ç½®æ–‡ä»¶ config/params.py
COUNTY_MODEL_CONFIG = {
    "input_size": 30,           # æ‰©å±•ç‰¹å¾ç»´åº¦
    "hidden_size": 256,         # éšè—å±‚å¤§å°
    "num_layers": 3,            # æ¨¡å‹å±‚æ•°
    "num_classes": 4,           # 4ä¸ªé£é™©ç­‰çº§
    "dropout": 0.3,             # Dropoutç‡
    "county_count": 137,        # å±±ä¸œå¿çº§æ•°é‡
    "county_embedding_dim": 16, # å¿çº§åµŒå…¥ç»´åº¦
    "spatial_attention": True,   # ç©ºé—´æ³¨æ„åŠ›
    "model_type": "enhanced_lstm"  # æ¨¡å‹ç±»å‹
}

COUNTY_TRAIN_CONFIG = {
    "batch_size": 32,           # æ‰¹æ¬¡å¤§å°
    "num_epochs": 200,          # è®­ç»ƒè½®æ•°
    "learning_rate": 0.001,     # å­¦ä¹ ç‡
    "seq_length": 12,           # 12ä¸ªæœˆæ—¶é—´åºåˆ—
    "patience": 15,             # æ—©åœè€å¿ƒå€¼
    "weight_decay": 1e-4,       # æƒé‡è¡°å‡
}
```

### æ­¥éª¤3: è®­ç»ƒç­–ç•¥

```python
# è®­ç»ƒæ•°æ®æ ¼å¼
train_data = {
    'features': torch.tensor([[[30ç»´ç‰¹å¾]]]),  # [batch_size, seq_len, input_size]
    'county_ids': torch.tensor([370101, 370102, ...]),  # å¿çº§ID
    'labels': torch.tensor([0, 1, 2, 0, 3, ...]),  # é£é™©ç­‰çº§
    'spatial_adjacency': adjacency_matrix  # ç©ºé—´å…³ç³»
}

# è®­ç»ƒå¾ªç¯
def train_county_model(model, train_loader, optimizer, criterion):
    model.train()
    total_loss = 0
    
    for batch in train_loader:
        features = batch['features']
        county_ids = batch['county_ids']
        labels = batch['labels']
        adjacency = batch['adjacency']
        
        optimizer.zero_grad()
        outputs = model(features, county_ids, adjacency)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    return total_loss / len(train_loader)
```

### æ­¥éª¤4: é¢„æµ‹å‡½æ•°

```python
def predict_shandong_counties(model, date_features, adjacency_matrix):
    """
    é¢„æµ‹æ•´ä¸ªå±±ä¸œçœå„å¿çš„ç¾å›½ç™½è›¾é£é™©
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        date_features: æŒ‡å®šæ—¶é—´ç‰¹å¾ï¼ˆæœˆåº¦æ°”è±¡æ•°æ®ç­‰ï¼‰
        adjacency_matrix: å¿çº§é‚»æ¥çŸ©é˜µ
    
    Returns:
        predictions: åŒ…å«137ä¸ªå¿é¢„æµ‹ç»“æœçš„å­—å…¸
    """
    model.eval()
    predictions = {}
    
    for county_id in range(370101, 370101 + 137):  # å±±ä¸œå¿çº§IDèŒƒå›´
        # å‡†å¤‡è¯¥å¿çš„è¾“å…¥ç‰¹å¾
        county_features = prepare_county_features(county_id, date_features)
        
        # æ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            output = model(
                county_features.unsqueeze(0),  # æ·»åŠ batchç»´åº¦
                torch.tensor([county_id]),
                adjacency_matrix
            )
            risk_prob = F.softmax(output, dim=-1)
            risk_level = torch.argmax(risk_prob)
        
        predictions[county_id] = {
            'risk_level': risk_level.item(),
            'probability': risk_prob.max().item(),
            'county_name': get_county_name(county_id),
            'risk_probabilities': risk_prob.squeeze().tolist()
        }
    
    return predictions

def generate_risk_map(predictions):
    """
    ç”Ÿæˆé£é™©ç­‰çº§å¯è§†åŒ–
    """
    risk_map = {
        'high_risk': [],
        'medium_risk': [], 
        'low_risk': [],
        'no_risk': []
    }
    
    for county_id, pred in predictions.items():
        risk_level = pred['risk_level']
        if risk_level == 3:
            risk_map['high_risk'].append(pred['county_name'])
        elif risk_level == 2:
            risk_map['medium_risk'].append(pred['county_name'])
        elif risk_level == 1:
            risk_map['low_risk'].append(pred['county_name'])
        else:
            risk_map['no_risk'].append(pred['county_name'])
    
    return risk_map
```

---

## ğŸ’¡ å®æ–½å»ºè®®

### 1. æ•°æ®æ”¶é›†ä¼˜å…ˆçº§
1. **é«˜ä¼˜å…ˆçº§**ï¼šæ°”è±¡æ•°æ®ã€å†å²å‘ç”Ÿæ•°æ®ã€åœ°ç†åæ ‡
2. **ä¸­ä¼˜å…ˆçº§**ï¼šæ¤è¢«æŒ‡æ•°ã€äººå£æ•°æ®
3. **ä½ä¼˜å…ˆçº§**ï¼šç»æµæ•°æ®ã€è¯¦ç»†åœ°å½¢æ•°æ®

### 2. æ¨¡å‹é€‰æ‹©å»ºè®®
- **å¿«é€Ÿå®æ–½**ï¼šæ–¹æ¡ˆ1ï¼ˆç©ºé—´å¢å¼ºå‹BiLSTMï¼‰
- **æœ€ä½³æ•ˆæœ**ï¼šæ–¹æ¡ˆ3ï¼ˆé›†æˆæ¨¡å‹ï¼‰
- **ç ”ç©¶å¯¼å‘**ï¼šæ–¹æ¡ˆ2ï¼ˆå›¾ç¥ç»ç½‘ç»œï¼‰

### 3. åˆ†æ­¥å®æ–½è®¡åˆ’
1. **ç¬¬1é˜¶æ®µ**ï¼šæ•°æ®æ”¶é›†å’Œé¢„å¤„ç†ï¼ˆ2-3å‘¨ï¼‰
2. **ç¬¬2é˜¶æ®µ**ï¼šæ¨¡å‹æ¶æ„ä¿®æ”¹å’Œè®­ç»ƒï¼ˆ3-4å‘¨ï¼‰
3. **ç¬¬3é˜¶æ®µ**ï¼šé¢„æµ‹éªŒè¯å’Œè°ƒä¼˜ï¼ˆ2-3å‘¨ï¼‰
4. **ç¬¬4é˜¶æ®µ**ï¼šå¯è§†åŒ–å’Œéƒ¨ç½²ï¼ˆ1-2å‘¨ï¼‰

### 4. éªŒè¯æ–¹æ³•
- **æ—¶é—´åºåˆ—éªŒè¯**ï¼šä½¿ç”¨å†å²æ•°æ®éªŒè¯é¢„æµ‹å‡†ç¡®æ€§
- **äº¤å‰éªŒè¯**ï¼šç©ºé—´äº¤å‰éªŒè¯éªŒè¯æ³›åŒ–èƒ½åŠ›
- **ä¸“å®¶è¯„ä¼°**ï¼šé‚€è¯·æ¤ä¿ä¸“å®¶è¯„ä¼°é¢„æµ‹ç»“æœåˆç†æ€§

### 5. é£é™©æ§åˆ¶
- **æ•°æ®è´¨é‡**ï¼šç¡®ä¿è¾“å…¥æ•°æ®çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
- **æ¨¡å‹è¿‡æ‹Ÿåˆ**ï¼šä½¿ç”¨æ—©åœã€æ­£åˆ™åŒ–ã€Dropoutç­‰æŠ€æœ¯
- **è®¡ç®—èµ„æº**ï¼šåˆç†é…ç½®GPUå†…å­˜å’Œè®¡ç®—èµ„æº

é€šè¿‡ä»¥ä¸Šä¿®æ”¹ï¼Œä½ çš„æ¨¡å‹å°†èƒ½å¤Ÿï¼š
- ä»ç‚¹çº§åˆ«é¢„æµ‹å‡çº§åˆ°å¿çº§å°ºåº¦é¢„æµ‹
- åŒæ—¶è€ƒè™‘æ—¶é—´åºåˆ—ç‰¹å¾å’Œç©ºé—´ä¼ æ’­ç‰¹å¾
- è¾“å‡ºæ•´ä¸ªå±±ä¸œçœ137ä¸ªå¿çš„ç¾å›½ç™½è›¾é£é™©é¢„æµ‹
- æä¾›å¯è§†åŒ–çš„é£é™©åˆ†å¸ƒå›¾

è¿™ä¸ªæ–¹æ¡ˆæ—¢ä¿ç•™äº†ä½ ç°æœ‰BiLSTMæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œåˆå¢åŠ äº†ç©ºé—´é¢„æµ‹èƒ½åŠ›ï¼Œéå¸¸é€‚åˆå¿çº§å°ºåº¦çš„å®³è™«é£é™©é¢„æµ‹ä»»åŠ¡ã€‚